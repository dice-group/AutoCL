# All of the best hyperparameter settings are shown here
### Best results per learning problem obtained from EvoLearner after HPO in terms of max_runtime, tournament_size, height_limit, card_limit, use_data_properties, use_inverse, quality_func, value_splitter, ğ¹1-measure and Accuracy. The first line of each learning problem represents the best hyperparameters and results before HPO, the second line represents the best hyperparameters and results after HPO. The results are the best among the 3 runs:
<img width="614" alt="Evolearner" src="https://github.com/dice-group/AutoCL/blob/main/HPO/Evolearner%20HPO.png">


After EvoLearner with HPO which shown in Table 8, we can observe an improvement in quality scores on Carcinogenesis, Hepatitis, Mammographic, and Pyrimidine. In particular, for dataset Carcinogenesis, the ğ¹1-measure improved by 6% and ğ´ğ‘ğ‘ğ‘¢ğ‘Ÿğ‘ğ‘ğ‘¦ improved by 10% after HPO. Similarly, excellent performance is also reflected in Pyrimidine: the ğ¹1-measure is almost 16% better. Family, NCTRER, Mutagenesis and Premier League keep the best ğ¹1-measure and ğ´ğ‘ğ‘ğ‘¢ğ‘Ÿğ‘ğ‘ğ‘¦ before and after HPO, after some values of hyperparameter changed.
Then we continue to analyse the changes in scoring criteria in conjunction with the value of the hyperparameter. From this table, it can be observed that the optimal running time of all datasets is much smaller than the original, which proves that HPO accelerates the learning time of the concept learner. Some datasets like Carcinogenesis, Hepatitis, the best value of hyperparameter including the tournament_size,height-limit,card-limit are different from the original default values. In the evolutionary algorithm EvoLearner, all of these values have an effect on each other, and when the number of tournaments becomes more or less, it will affect the algorithmâ€™s decision-making over include.
A more satisfactory result is obtained when the default value of ğ‘‡ğ‘Ÿğ‘¢ğ‘’ is selected for use_data_properties has been shown in EvoLearner. At the same time, the hyperparameter value_splitter only works when use_data_properties was set to ğ‘‡ğ‘Ÿğ‘¢ğ‘’. Furthermore, we find that different values of this value_splitter that appear in the optimum parameters may not greatly influence our result. For the hyperparameter quality_func, the ğ¹1 appears same times with ğ´ğ‘ğ‘ğ‘¢ğ‘Ÿğ‘ğ‘ğ‘¦. Lastly, the value of use_inverse, ğ‘‡ğ‘Ÿğ‘¢ğ‘’ and ğ¹ğ‘ğ‘™ğ‘ ğ‘’ shown half.

### Best results per learning problem obtained from OCEL after HPO in terms of max_runtime in seconds, max_num_of_concepts_tested,iter_bound,quality_func, ğ¹1_measure and Accuracy. The first line of each learning problem represents the best hyperparameters and results before HPO, the second line represents the best hyperparameters and results after HPO. The results are the best among the 3 runsï¼š
<img width="614" alt="Ocel" src="https://github.com/AutoCL2023/AutoCL/blob/main/OCEL%20HPO.png">

In OCEL with HPO, we can find that the optimal value of max-run-time is reduced on all datasets, and the ğ¹1-measure as well as the ğ´ğ‘ğ‘ğ‘¢ğ‘Ÿğ‘ğ‘ğ‘¦ is improved on four of them, especially for the large dataset with more atoms Premier League, where the ğ¹1-measure and ğ´ğ‘ğ‘ğ‘¢ğ‘Ÿğ‘ğ‘ğ‘¦ are improved by at least 50%.
On other parameters such as max_num_of_concepts_tested, iter_bound, the optimal values are also very different from the original defaults, and the reduction in these values means that the concept learner is able to use a narrower learning range to get the results we want.

### Best results per learning problem obtained from CELOE after HPO in terms of max_runtime in seconds, max_num_of_concepts_tested,iter_bound,quality_func, ğ¹1_measure and Accuracy. The first line of each learning problem represents the best hyperparameters and results before HPO, the second line represents the best hyperparameters and results after HPO. The results are the best among the 3 runsï¼š
<img width="614" alt="Celoe" src="https://github.com/AutoCL2023/AutoCL/blob/main/CELOE%20HPO.png">
When HPO was applied to CELOE, it produced similar results as on OCEL: the conceptual learner improved learn- ing performance on more than half of the datasets while reducing the runtime and learning range. On the Carcinogenesis, Famliy datasets, ğ¹1-measure, and ğ´ğ‘ğ‘ğ‘¢ğ‘Ÿğ‘ğ‘ğ‘¦ still produced quality scores similar to the original data.
