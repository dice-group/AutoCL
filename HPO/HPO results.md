#All of the best hyperparameter settings are shown here
### Best results per learning problem obtained from EvoLearner after HPO in terms of max_runtime, tournament_size, height_limit, card_limit, use_data_properties, use_inverse, quality_func, value_splitter, ğ¹1-measure and ğ´ğ‘ğ‘ğ‘¢ğ‘Ÿğ‘ğ‘ğ‘¦. The first line of each learning problem represents the best hyperparameters and results before HPO, the second line represents the best hyperparameters and results after HPO. The results are the best among the 3 runs:
<img width="614" alt="Evolearner" src="https://github.com/AutoCL2023/AutoCL/blob/main/Evolearner%20HPO.png">
###Best results per learning problem obtained from OCEL after HPO in terms of max_runtime in seconds, max_num_of_concepts_tested,iter_bound,quality_func, ğ¹1_measure and Accuracy. The first line of each learning problem represents the best hyperparameters and results before HPO, the second line represents the best hyperparameters and results after HPO. The results are the best among the 3 runsï¼š


<img width="614" alt="Ocel" src="https://github.com/AutoCL2023/AutoCL/blob/main/OCEL%20HPO.png">

###Best results per learning problem obtained from CELOE after HPO in terms of max_runtime in seconds, max_num_of_concepts_tested,iter_bound,quality_func, ğ¹1_measure and Accuracy. The first line of each learning problem represents the best hyperparameters and results before HPO, the second line represents the best hyperparameters and results after HPO. The results are the best among the 3 runsï¼š<img width="614" alt="Celoe" src="https://github.com/AutoCL2023/AutoCL/blob/main/CELOE%20HPO.png">
